{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP2FLGC1yx5OD1Rdegg2/JL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waltechel/KaggleStudy20220103/blob/master/chapter08/KoGPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install pydantic\n",
        "!pip install opyrator"
      ],
      "metadata": {
        "id": "4OsRX2hCou-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "Wcf2qu1QooBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWN9yPO6omjM"
      },
      "outputs": [],
      "source": [
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    \"skt/kogpt2-base-v2\",\n",
        "    bos_token='</s>',\n",
        "    eos_token='</s>',\n",
        "    unk_token='<unk>',\n",
        "    pad_token='<pad>',\n",
        "    mask_token='<mask>') \n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- í† í¬ë‚˜ì´ì§• ì‚¬ë¡€"
      ],
      "metadata": {
        "id": "GungaWoZt1aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")"
      ],
      "metadata": {
        "id": "VDxNFCx-tzOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'ìœ¤ì„ì—´ ëŒ€ ì´ì¬ëª…, ì´ì¬ëª… ëŒ€ ìœ¤ì„ì—´ë¡œ ì••ì¶•ë˜ëŠ” ì´ë²ˆ ëŒ€ì„ ì—ì„œëŠ”'\n",
        "input_ids = tokenizer.encode(text)\n",
        "gen_ids = model.generate(torch.tensor([input_ids]),\n",
        "                           max_length=128,\n",
        "                           repetition_penalty=2.0,\n",
        "                           pad_token_id=tokenizer.pad_token_id,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           bos_token_id=tokenizer.bos_token_id,\n",
        "                           use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0,:].tolist())\n",
        "print(generated)"
      ],
      "metadata": {
        "id": "Mo9rN38kt4Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MY4tqtGgq1IK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}